# -*- coding: utf-8 -*-
"""FemAI1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H4Ordz_f8lWdCO0x2CJnSW4Kd_bbnU4t
"""

!pip install -U langchain langgraph
!pip install -U langchain_openai langchain_google_genai
import os
from getpass import getpass
os.environ["GOOGLE_API_KEY"]=getpass("Enter your gemini api key:")
os.environ["OPENAI_API_KEY"]=getpass("Enter your openai api key:")

from typing import TypedDict
class State(TypedDict):
  problem:str
  response_gem:str
  response_openai:str

!pip install google-ai-generativelanguage==0.6.15
!pip install -U langchain_openai
!pip install -qU \
langchain-google-genai==2.1.4 \
  langgraph==0.4.5 \
  python-dotenv \
  google-ai-generativelanguage==0.6.18 \
  filetype \
  ormsgpack

from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import START,END,StateGraph
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI

def feallmsolver(state:State)->State:

  print("Entering gemini llm chain")
  stateprompt=ChatPromptTemplate.from_template("You are a fea Engineer ,you stand at the peak of your career as you solve fea sums without any errors,now given an finite element problem in description solve for whats asked in the problem give numerical answer,make sure you give only one answer, even if a question comes where you have subdivisions dont solve all of them just solve the first subdivision of it and give me the answer in numerical value along with 5 decimals after point,i want you to be very very accurate in giving response,here is the problem description {Description},make sure you do not add any other description as text,trying to explain and all ,i want just the answer number alone, this is the most important rule comply to this")
  llm1=ChatGoogleGenerativeAI(model="gemini-1.5-flash")
  chain1=stateprompt|llm1
  initial_gemini_respose=chain1.invoke({"Description":state["problem"]})

  print("Entering openai llm chain")
  llm2=ChatOpenAI(model="gpt-3.5-turbo")
  chain2=stateprompt|llm2
  initial_openai_response=chain2.invoke({"Description":state["problem"]})

  return{
      "problem":state["problem"],
      "response_gem":initial_gemini_respose.content,
      "response_openai":initial_openai_response.content
  }

workflow=StateGraph(State)
workflow.add_node("feallmsolvernode",feallmsolver)
workflow.add_edge(START,"feallmsolvernode")
workflow.add_edge("feallmsolvernode",END)
app=workflow.compile()

query="A single-degree-of-freedom system has mass m=2kg and spring stiffness k=1000N/m .Find: The natural frequency of vibration in radians per second"
final_result=app.invoke({"problem":query})
print("Printing Final results....")
print(final_result)

print(final_result["response_gem"])
print(final_result["response_openai"])
finalres1=final_result["response_gem"]
finalres2=final_result["response_openai"]

import re

def extract_number(s):
    """Extract first valid float number from string `s`."""
    match = re.search(r"[-+]?\d*\.\d+|\d+", s)
    return float(match.group()) if match else None

# Collect all responses from final_result dynamically
response_values = []
for key, value in final_result.items():
    if key.startswith("response_"):
        num = extract_number(value)
        if num is not None:
            response_values.append(num)

# Calculate average (can later be replaced by weighted average)
if response_values:
    average_response = sum(response_values) / len(response_values)
    print(f"\nAverage of all model responses: {average_response:.5f}")
else:
    print("No valid numeric responses found.")

